## spacesavers2_finddup

This takes in the `ls_out` generated by `spacesavers2_ls` and processes it to:

- find duplicates
- create per-user summary reports for each user (and all users).

### Inputs

- `--lsout` is the output file from  `spacesavers2_ls`. Thus, `spacesavers2_ls` needs to be run before running `spacesavers2_finddup`.
- `--maxdepth` maximum folder depth upto which reports are aggregated
- `--outdir` path to the output folder
- `--prefix` prefix to be added to the output file names eg. date etc.
- `--duplicatesonly` only report duplicates in the `.files.gz` output files. This saves a lot of disc space. (Highly recommended!)
- `--quota` defines the size of the overall file mount. (eg. 200 TB for `/data/CCBR` on BIOWULF.) OccScore is dependent on this and should be provided appropriately for accurate results.

```bash
% ./spacesavers2_finddup --help
spacesavers2_finddup:00000.01s:version: v0.5
usage: spacesavers2_finddup [-h] -f LSOUT [-d MAXDEPTH] [-o OUTDIR] [-p PREFIX] [-q QUOTA] [-z | --duplicatesonly | --no-duplicatesonly]

spacesavers2_finddup: find duplicates

options:
  -h, --help            show this help message and exit
  -f LSOUT, --lsout LSOUT
                        spacesavers2_ls output from STDIN or from file
  -d MAXDEPTH, --maxdepth MAXDEPTH
                        folder max. depth upto which reports are aggregated
  -o OUTDIR, --outdir OUTDIR
                        output folder
  -p PREFIX, --prefix PREFIX
                        prefix for all output files
  -q QUOTA, --quota QUOTA
                        total quota of the mount eg. 200 TB for /data/CCBR
  -z, --duplicatesonly, --no-duplicatesonly
                        Print only duplicates to per user output file.

Version:
    v0.5
Example:
    > spacesavers2_finddup -f /output/from/spacesavers2_ls -o /path/to/output/folder -d 7 -q 10
```

### Outputs

After completion of run, `spacesavers2_finddup` creates `.files.gz` (list of duplicate files) and `.summary.txt` (overall stats at various depths) files in the provided output folder. Here are the details:

#### Duplicates

`spacesavers2_finddup` uses the following logic to find duplicates:

- Bin files by their top (and bottom) xxHashes irrespective of user id (allusers mode)
- Check if each bin has unique sized files. If a bin has more than 1 size, then it needs to be binned further. Sometimes, xxHash of top and bottom chunks also gives the same combination of hash for differing files. These files will have different sizes. Hence, re-bin them accordingly.
- If same size, then check inodes. If all files in the same bin have the same inode, then these are just hard-links. But, if there are multiple inodes, then we have **duplicates**!
- If we have duplicates, then `spacesavers2_finddup` keeps track of number of duplicates per bin. Number of duplicates is equal to number of inodes in each bin minus one.
- If we have duplicates, then the oldest find is identified and considered to be the original file. All other files are marked _duplicate_, irrespective of user id.
- duplicate files are reported in gzip format with the following columns for all users and per-user basis

Here is what the `.files.gz` file columns (space-separated) represent:

| Column | Description                                      |
| ------ | ------------------------------------------------ |
| 1      | top chunk and bottom chunk hashes separated by "#" |
| 2      | separator ":"                                    |
| 3      | Number of duplicates                             |
| 4      | Size of each file                                |
| 5      | List of users duplicates serapated by "##"       |

Each file in the last column above is ":" separated with the same 13 items as described in the `ls_out` file. The only difference is that the user id and group id are now replaced by user name and group name.

Along with creating one `.files.gz` and `.summary.txt` file per user encountered, `spacesavers2_finddup` also generates a `allusers.files.gz` file for all users combined. This file is later used by `spacesavers2_blamematrix` as input.

#### Summaries

Summaries, files ending with `.summary.txt` are collected and reported for all users (`allusers.summary.txt`) and per-user (`USERNAME.summary.txt`) basis for user-defined depth (and beyond). The columns (tab-delimited) in the summary file:

| Column | Description                           |
| ------ | ------------------------------------- |
| 1      | absolute path                         |
| 2      | total bytes                           |
| 3      | duplicate bytes                       |
| 4      | percent duplicate bytes               |
| 5      | total files                           |
| 6      | duplicate files                       |
| 7      | percent duplicate files               |
| 8      | average file age of all files (days)  |
| 9      | average file age of duplicates (days) |
| 10     | AgeScore                              |
| 11     | DupScore                              |
| 12     | OccScore                              |
| 13     | OverallScore                          |

For columns 10 through 13, the same logic is used as [spacesavers](https://ccbr.github.io/spacesavers/usage/df/).

